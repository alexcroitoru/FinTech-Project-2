{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "35f96a1e-1f80-4ec8-b645-b5ff88a6ff51",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import praw\n",
    "from praw.models import MoreComments\n",
    "import pandas as pd\n",
    "from requests import Session\n",
    "import datetime as dt\n",
    "from datetime import date, timedelta\n",
    "from psaw import PushshiftAPI\n",
    "\n",
    "\n",
    "def get_date(created):\n",
    "    return dt.datetime.fromtimestamp(created)\n",
    "\n",
    "#___________________________________________________________________________________________________________\n",
    "def redditing(start_date, end_date):\n",
    "    try:\n",
    "        # define connection variables\n",
    "        reddit = praw.Reddit(\n",
    "            client_id=\"ZjPaBT8ar8gCw7fwxI3d-Q\",\n",
    "            client_secret=\"HkSP6Qmf5cC5Pryh1e8JVasGiWo5Xg\",\n",
    "            password=\"1440falcon\",  # pass Session\"\n",
    "            user_agent=\"API\",\n",
    "            username=\"alexcroitoru\")\n",
    "\n",
    "\n",
    "        api = PushshiftAPI()\n",
    "\n",
    "        # define dates for query\n",
    "        # start_time = int(dt.datetime(2020, month, day_start).timestamp())\n",
    "        # end_time = int(dt.datetime(2020, month, day_end).timestamp())\n",
    "\n",
    "        # begin query\n",
    "        query = api.search_submissions(after=start_date, before=end_date, subreddit = \"wallstreetbets\")\n",
    "\n",
    "        # create query and append submissions (threads)\n",
    "        submissions = list()\n",
    "        for element in query:\n",
    "            submissions.append(element.d_)\n",
    "\n",
    "        # convert list to dataframe\n",
    "        reddits = pd.DataFrame(submissions)\n",
    "\n",
    "        # filter on Daily Discussion Threads\n",
    "        reddit_api = reddits[reddits['title'].str.contains(\"Daily Discussion Thread\", regex=False)]\n",
    "\n",
    "        reddit_id = reddit_api.iloc[0]['id']\n",
    "\n",
    "        # pull id from DDT\n",
    "        submission = reddit.submission(id = f'{reddit_id}')\n",
    "\n",
    "        comments = list()\n",
    "        postlist = []\n",
    "        # Extract all comments\n",
    "        submission.comments.replace_more(limit=0)\n",
    "\n",
    "        #for comment in submission.comments.list():\n",
    "            #comments.append(comment.body.d_)\n",
    "            #reddit_comments = pd.DataFrame(comments)\n",
    "            #return(reddit_comments)\n",
    "            #return(comment.body)\n",
    "        # Create DF for comments and add Column Names    \n",
    "        for comment in submission.comments: \n",
    "                post = {}\n",
    "                post['Author'] = str(comment.author)\n",
    "                post['Comment'] = comment.body.encode('ascii', 'ignore').decode('ascii')\n",
    "                post['Score'] = int(comment.score)\n",
    "                post['Time Created'] = int(comment.created_utc)\n",
    "                postlist.append(post)\n",
    "\n",
    "                #print(postlist)\n",
    "\n",
    "        Postdf = pd.DataFrame(postlist)\n",
    "        return(Postdf)\n",
    "    except Exception as E:\n",
    "        print(E, day_start)\n",
    "        pass\n",
    "#___________________________________________________________________________________________________________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "70686123-45af-498b-910b-651559fa3bca",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-02-28\n",
      "single positional indexer is out-of-bounds 3\n",
      "2021-03-01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alexa\\anaconda3\\lib\\site-packages\\psaw\\PushshiftAPI.py:192: UserWarning: Got non 200 code 429\n",
      "  warnings.warn(\"Got non 200 code %s\" % response.status_code)\n",
      "C:\\Users\\alexa\\anaconda3\\lib\\site-packages\\psaw\\PushshiftAPI.py:180: UserWarning: Unable to connect to pushshift.io. Retrying after backoff.\n",
      "  warnings.warn(\"Unable to connect to pushshift.io. Retrying after backoff.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "single positional indexer is out-of-bounds 3\n",
      "2021-03-02\n",
      "2021-03-03\n",
      "2021-03-04\n",
      "2021-03-05\n",
      "2021-03-06\n",
      "single positional indexer is out-of-bounds 3\n",
      "2021-03-07\n",
      "single positional indexer is out-of-bounds 3\n",
      "2021-03-08\n",
      "2021-03-09\n",
      "2021-03-10\n"
     ]
    }
   ],
   "source": [
    "start_date = dt.date(2021, 2, 28)\n",
    "delta = dt.timedelta(days=1)\n",
    "window = start_date + dt.timedelta(days=2)\n",
    "end_date = dt.date(2021, 3, 10)\n",
    "\n",
    "append_data = []\n",
    "\n",
    "while start_date <= end_date:\n",
    "    print(start_date)\n",
    "    Postdf = pd.DataFrame(redditing(start_date=start_date, end_date=window))\n",
    "    append_data.append(Postdf)\n",
    "    start_date += delta\n",
    "    window+=delta\n",
    "    \n",
    "appended_data = pd.concat(append_data)\n",
    "_timestamp = appended_data[\"Time Created\"].apply(get_date)\n",
    "appended_data = appended_data.assign(timestamp = _timestamp)\n",
    "\n",
    "appended_data.to_excel('appended.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1e85bfe0-cc45-4a35-9c43-3081058c40b1",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-01-01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alexa\\anaconda3\\lib\\site-packages\\psaw\\PushshiftAPI.py:252: UserWarning: Not all PushShift shards are active. Query results may be incomplete\n",
      "  warnings.warn(shards_down_message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-01-02\n",
      "2020-01-03\n",
      "'title' 3\n"
     ]
    }
   ],
   "source": [
    "start_date = dt.date(2020, 1, 1)\n",
    "end_date = dt.date(2020, 1, 3)\n",
    "delta = dt.timedelta(days=1)\n",
    "\n",
    "append_data = []\n",
    "\n",
    "while start_date <= end_date:\n",
    "    print(start_date)\n",
    "    month = int(start_date.strftime('%m')[1])\n",
    "    day_start = int(start_date.strftime('%d')[1])\n",
    "    day_end = int(end_date.strftime('%d')[1])\n",
    "    Postdf = pd.DataFrame(redditing(start_date, end_date ))\n",
    "    append_data.append(Postdf)\n",
    "    start_date += delta\n",
    "    \n",
    "    \n",
    "appended_data = pd.concat(append_data)\n",
    "\n",
    "_timestamp = appended_data[\"Time Created\"].apply(get_date)\n",
    "appended_data = appended_data.assign(timestamp = _timestamp)\n",
    "#appended_data = appended_data.drop(columns=[\"Time Created\"])\n",
    "\n",
    "appended_data.to_excel('appended.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd4d5feb-9d26-4f51-8cba-f6f39b884884",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "month = start_date.strftime('%m')[1]\n",
    "\n",
    "while start_date <= end_date:\n",
    "    print(start_date)\n",
    "    appended_data = []\n",
    "    # day_start = 4\n",
    "    day_end = day_start + 1\n",
    "    Postdf = pd.DataFrame(redditing(month, start_day, end_day))\n",
    "    appended_data.append(Postdf)\n",
    "    start_date += delta\n",
    "    \n",
    "#for day_start in range(start_date, end_date):\n",
    "#    appended_data = []\n",
    "    # day_start = 4\n",
    "#    day_end = day_start + 1\n",
    "#    Postdf = pd.DataFrame(redditing(5, day_start, day_end))\n",
    "#    appended_data.append(Postdf)\n",
    "\n",
    "appended_data = pd.concat(appended_data)\n",
    "\n",
    "_timestamp = appended_data[\"Time Created\"].apply(get_date)\n",
    "appended_data = appended_data.assign(timestamp = _timestamp)\n",
    "appended_data = appended_data.drop(columns=[\"Time Created\"])\n",
    "\n",
    "appended_data.to_excel('appended.xlsx')\n",
    "\n",
    "    \n",
    "#Postdf = pd.DataFrame(redditing(5, 3, 4))\n",
    "#Postdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "23c8f430-3021-492b-90d1-9613e2e09bc3",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "start_date = dt.date(2020, 1, 1)\n",
    "end_date = dt.date(2020, 1, 2)\n",
    "delta = dt.timedelta(days=1)\n",
    "\n",
    "reddit = praw.Reddit(\n",
    "            client_id=\"ZjPaBT8ar8gCw7fwxI3d-Q\",\n",
    "            client_secret=\"HkSP6Qmf5cC5Pryh1e8JVasGiWo5Xg\",\n",
    "            password=\"1440falcon\",  # pass Session\"\n",
    "            user_agent=\"API\",\n",
    "            username=\"alexcroitoru\")\n",
    "\n",
    "\n",
    "api = PushshiftAPI()\n",
    "\n",
    "        # define dates for query\n",
    "        # start_time = int(dt.datetime(2020, month, day_start).timestamp())\n",
    "        # end_time = int(dt.datetime(2020, month, day_end).timestamp())\n",
    "\n",
    "        # begin query\n",
    "query = api.search_submissions(after=start_date, before=end_date, subreddit = \"wallstreetbets\")\n",
    "\n",
    "        # create query and append submissions (threads)\n",
    "submissions = list()\n",
    "for element in query:\n",
    "    submissions.append(element.d_)\n",
    "\n",
    "        # convert list to dataframe\n",
    "reddits = pd.DataFrame(submissions)\n",
    "\n",
    "        # filter on Daily Discussion Threads\n",
    "reddit_api = reddits[reddits['title'].str.contains(\"Daily Discussion Thread\", regex=False)]\n",
    "\n",
    "reddit_id = reddit_api.iloc[0]['id']\n",
    "\n",
    "        # pull id from DDT\n",
    "submission = reddit.submission(id = f'{reddit_id}')\n",
    "\n",
    "comments = list()\n",
    "postlist = []\n",
    "        # Extract all comments\n",
    "submission.comments.replace_more(limit=0)\n",
    "\n",
    "        #for comment in submission.comments.list():\n",
    "            #comments.append(comment.body.d_)\n",
    "            #reddit_comments = pd.DataFrame(comments)\n",
    "            #return(reddit_comments)\n",
    "            #return(comment.body)\n",
    "        # Create DF for comments and add Column Names    \n",
    "for comment in submission.comments: \n",
    "    post = {}\n",
    "    post['Author'] = str(comment.author)\n",
    "    post['Comment'] = comment.body.encode('ascii', 'ignore').decode('ascii')\n",
    "    post['Score'] = int(comment.score)\n",
    "    post['Time Created'] = int(comment.created_utc)\n",
    "    postlist.append(post)\n",
    "\n",
    "                #print(postlist)\n",
    "\n",
    "Postdf = pd.DataFrame(postlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "82c31f90-8101-47f4-9528-b2af6b4eabb1",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Author</th>\n",
       "      <th>Comment</th>\n",
       "      <th>Score</th>\n",
       "      <th>Time Created</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Master531</td>\n",
       "      <td>YTD losses reset again, lets try one more time</td>\n",
       "      <td>36</td>\n",
       "      <td>1577882625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TeslaLeafBlower</td>\n",
       "      <td>Markets closed today, due to Y20K computer gli...</td>\n",
       "      <td>28</td>\n",
       "      <td>1577884317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Juicymess</td>\n",
       "      <td>My brother has been long ACB since $10. Can we...</td>\n",
       "      <td>31</td>\n",
       "      <td>1577890298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cnastydawg</td>\n",
       "      <td>#I HEREBY DECLARE HANGOVERS ILLEGAL IN THE UNI...</td>\n",
       "      <td>27</td>\n",
       "      <td>1577880689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SmallPotGuest</td>\n",
       "      <td>A retard was forcibly removed from the doors o...</td>\n",
       "      <td>23</td>\n",
       "      <td>1577891161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>ISICKNEWTON</td>\n",
       "      <td>Someone really needs the market flat today, oh...</td>\n",
       "      <td>2</td>\n",
       "      <td>1577888816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>Agent248</td>\n",
       "      <td>Anyone looking to short tsla for earnings play?</td>\n",
       "      <td>2</td>\n",
       "      <td>1577895897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>gettendies</td>\n",
       "      <td>Happy New Year everyone!\\n\\nThinking about goi...</td>\n",
       "      <td>2</td>\n",
       "      <td>1577900529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>StonksGoUpOnly</td>\n",
       "      <td>I would just like to point out that that after...</td>\n",
       "      <td>2</td>\n",
       "      <td>1577905549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>Midgetfarm</td>\n",
       "      <td>2020 here we are\\n\\nu/hinduhamma sucking cock ...</td>\n",
       "      <td>3</td>\n",
       "      <td>1577907723</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>140 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              Author                                            Comment  \\\n",
       "0          Master531     YTD losses reset again, lets try one more time   \n",
       "1    TeslaLeafBlower  Markets closed today, due to Y20K computer gli...   \n",
       "2          Juicymess  My brother has been long ACB since $10. Can we...   \n",
       "3         Cnastydawg  #I HEREBY DECLARE HANGOVERS ILLEGAL IN THE UNI...   \n",
       "4      SmallPotGuest  A retard was forcibly removed from the doors o...   \n",
       "..               ...                                                ...   \n",
       "135      ISICKNEWTON  Someone really needs the market flat today, oh...   \n",
       "136         Agent248    Anyone looking to short tsla for earnings play?   \n",
       "137       gettendies  Happy New Year everyone!\\n\\nThinking about goi...   \n",
       "138   StonksGoUpOnly  I would just like to point out that that after...   \n",
       "139       Midgetfarm  2020 here we are\\n\\nu/hinduhamma sucking cock ...   \n",
       "\n",
       "     Score  Time Created  \n",
       "0       36    1577882625  \n",
       "1       28    1577884317  \n",
       "2       31    1577890298  \n",
       "3       27    1577880689  \n",
       "4       23    1577891161  \n",
       "..     ...           ...  \n",
       "135      2    1577888816  \n",
       "136      2    1577895897  \n",
       "137      2    1577900529  \n",
       "138      2    1577905549  \n",
       "139      3    1577907723  \n",
       "\n",
       "[140 rows x 4 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Postdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78592cf2-50ae-45b2-be14-c365de9c5fb3",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "date_datetime = pd.to_datetime(date_str)\n",
    "date_datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "453b0c29-2739-45b8-bd78-ff0e9969dd1f",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "next_day_datetime = date_datetime + pd.Timedelta(days = 1)\n",
    "current_day_string = date_datetime.strftime('%Y-%m-%d')\n",
    "next_day_string = next_day_datetime.strftime('%Y-%m-%d')\n",
    "current_day_string"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b749b435-c60f-405c-b39f-fd248b568bd5",
   "metadata": {},
   "source": [
    "\n",
    "import praw\n",
    "from praw.models import MoreComments\n",
    "import pandas as pd\n",
    "from requests import Session\n",
    "import datetime as dt\n",
    "from datetime import date, timedelta\n",
    "from psaw import PushshiftAPI\n",
    "\n",
    "\n",
    "def redditing(year, month, day_start, day_end):\n",
    "    reddit = praw.Reddit(client_id=\"ZjPaBT8ar8gCw7fwxI3d-Q\",\n",
    "                         client_secret=\"HkSP6Qmf5cC5Pryh1e8JVasGiWo5Xg\",\n",
    "                         password=\"1440falcon\",\n",
    "                         user_agent=\"API\",\n",
    "                         username=\"alexcroitoru\")\n",
    "    \n",
    "    api = PushshiftAPI()\n",
    "\n",
    "    start_time = int(dt.datetime(year, month, day_start).timestamp())\n",
    "    end_time = int(dt.datetime(year, month, day_end).timestamp())\n",
    "    \n",
    "    query = api.search_submissions(after=start_time, before=end_time, subreddit = \"wallstreetbets\")\n",
    "    \n",
    "    submissions = list()\n",
    "    for element in query:\n",
    "        submissions.append(element.d_)\n",
    "        \n",
    "    reddits = pd.DataFrame(submissions)\n",
    "\n",
    "    reddit_api = reddits[reddits['title'].str.contains(\"Daily Discussion Thread\", regex=False)]\n",
    "    alex = reddit_api.iloc[0:10]['id']\n",
    "    \n",
    "    submission = reddit.submission(id= f'{alex}')\n",
    "    \n",
    "    submission.comments.replace_more(limit=0)\n",
    "    for comment in submission.comments.list():\n",
    "        print(comment.body)\n",
    "    for comment in submission.comments: \n",
    "            post = {}\n",
    "            post['Author'] = str(comment.author)\n",
    "            post['Comment'] = comment.body.encode('ascii', 'ignore').decode('ascii')\n",
    "            post['Score'] = int(comment.score)\n",
    "            postlist.append(post)\n",
    "        \n",
    "redditing(2020, 1, 1, 2)\n",
    "Postdf = pd.DataFrame(postlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7abcbfdc-03e9-4d5f-afb3-2867c0bcd5a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5eb93d2-bb9d-4fe4-98dc-28de64a6b11b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
