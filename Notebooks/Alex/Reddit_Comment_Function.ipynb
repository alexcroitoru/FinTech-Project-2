{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fa095876-e607-4de2-92f9-9cdfa4bf197a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import praw\n",
    "import glob\n",
    "import os\n",
    "from praw.models import MoreComments\n",
    "import pandas as pd\n",
    "from requests import Session\n",
    "import datetime as dt\n",
    "from datetime import date, timedelta\n",
    "from psaw import PushshiftAPI\n",
    "import emoji\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "27a348aa-b876-40bc-94a4-266d7db2cf30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining Functions\n",
    "\n",
    "def get_date(created):\n",
    "    return dt.datetime.fromtimestamp(created)\n",
    "\n",
    "#___________________________________________________________________________________________________________\n",
    "def redditing(start_date, end_date):\n",
    "    try:\n",
    "        # define connection variables\n",
    "        reddit = praw.Reddit(\n",
    "            client_id=\"ZjPaBT8ar8gCw7fwxI3d-Q\",\n",
    "            client_secret=\"HkSP6Qmf5cC5Pryh1e8JVasGiWo5Xg\",\n",
    "            password=\"1440falcon\",  # pass Session\"\n",
    "            user_agent=\"API\",\n",
    "            username=\"alexcroitoru\")\n",
    "\n",
    "\n",
    "        api = PushshiftAPI()\n",
    "\n",
    "        # define dates for query\n",
    "        # start_time = int(dt.datetime(2020, month, day_start).timestamp())\n",
    "        # end_time = int(dt.datetime(2020, month, day_end).timestamp())\n",
    "\n",
    "        # begin query\n",
    "        query = api.search_submissions(after=start_date, \n",
    "                                       before=end_date, \n",
    "                                       subreddit = \"wallstreetbets\")\n",
    "\n",
    "        # create query and append submissions (threads)\n",
    "        submissions = list()\n",
    "        for element in query:\n",
    "            submissions.append(element.d_)\n",
    "\n",
    "        # convert list to dataframe\n",
    "        reddits = pd.DataFrame(submissions)\n",
    "\n",
    "        # filter on Daily Discussion Threads\n",
    "        searchfor = ['Daily Popular Tickers Thread', \n",
    "                     'What Are Your Moves Tomorrow', \n",
    "                     'Daily Discussion Thread', \n",
    "                     'Weekend Discussion Thread']\n",
    "\n",
    "       #reddit_api = reddits[reddits['title'].str.contains('|'.join(searchfor))]\n",
    "        reddit_api = reddits[reddits['title'].str.contains(\"Daily Discussion Thread\", regex=False)]\n",
    "\n",
    "        reddit_id = reddit_api.iloc[0]['id']\n",
    "\n",
    "        # pull id from DDT\n",
    "        submission = reddit.submission(id = f'{reddit_id}')\n",
    "\n",
    "        comments = list()\n",
    "        postlist = []\n",
    "        # Extract all comments\n",
    "        submission.comments.replace_more(limit=0)\n",
    "\n",
    "        #for comment in submission.comments.list():\n",
    "            #comments.append(comment.body.d_)\n",
    "            #reddit_comments = pd.DataFrame(comments)\n",
    "            #return(reddit_comments)\n",
    "            #return(comment.body)\n",
    "        # Create DF for comments and add Column Names    \n",
    "        for comment in submission.comments: \n",
    "                post = {}\n",
    "                post['Submission'] = str(comment.submission)\n",
    "                post['Author'] = str(comment.author)\n",
    "                post['Comment'] = comment.body.encode('ascii', 'ignore').decode('ascii')\n",
    "                post['Score'] = int(comment.score)\n",
    "                post['Time Created'] = int(comment.created_utc)\n",
    "                postlist.append(post)\n",
    "\n",
    "                #print(postlist)\n",
    "\n",
    "        Postdf = pd.DataFrame(postlist)\n",
    "        return(Postdf)\n",
    "    except Exception as E:\n",
    "        print(E, starting_day)\n",
    "        pass\n",
    "#___________________________________________________________________________________________________________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ca369ec4-2445-4c7e-92e8-95f91e478643",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-08-15\n",
      "2021-08-16\n",
      "2021-08-17\n",
      "2021-08-18\n"
     ]
    }
   ],
   "source": [
    "# Define Start Date and End Date / Weekends are not ran and will throw a warning while running\n",
    "first = 5\n",
    "second = first+2\n",
    "\n",
    "start_date = dt.date(2021, 8, 15)\n",
    "delta = dt.timedelta(days=1)\n",
    "window = start_date + dt.timedelta(days=2)\n",
    "end_date = dt.date(2021, 8, 18)\n",
    "\n",
    "starting_day = start_date.strftime('%d')[0:2]\n",
    "ending_day = end_date.strftime('%d')[0:2]\n",
    "\n",
    "month = start_date.strftime('%m')[1]\n",
    "\n",
    "append_data = []\n",
    "\n",
    "while start_date <= end_date:\n",
    "    print(start_date)\n",
    "    Postdf = pd.DataFrame(redditing(start_date=start_date, end_date=window))\n",
    "    append_data.append(Postdf)\n",
    "    start_date += delta\n",
    "    window+=delta\n",
    "    \n",
    "appended_data = pd.concat(append_data)\n",
    "_timestamp = appended_data[\"Time Created\"].apply(get_date)\n",
    "appended_data = appended_data.assign(timestamp = _timestamp)\n",
    "appended_data = appended_data.drop(columns=[\"Time Created\"])\n",
    "\n",
    "excel_name = f'{month}_{starting_day}_{ending_day}_comments'\n",
    "appended_data.to_csv(f'{excel_name}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "41568737-59bb-45cd-ace4-8edf47f05ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"../comment_folder\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "79f2fef6-4ebf-4484-9029-31de887d1449",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['6_15_25_comments.csv',\n",
       " '6_25_05_comments.csv',\n",
       " '7_05_15_comments.csv',\n",
       " '7_15_25_comments.csv',\n",
       " '7_25_01_comments.csv',\n",
       " '8_2_17_comments.csv']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extension = 'csv'\n",
    "all_filenames = [i for i in glob.glob('*comments.{}'.format(extension))]\n",
    "all_filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e60c1125-4510-4af4-a234-f519fd519f48",
   "metadata": {},
   "outputs": [],
   "source": [
    "#combine all files in the list\n",
    "combined_csv = pd.concat([pd.read_csv(f) for f in all_filenames])\n",
    "#export to csv\n",
    "combined_csv.to_csv( \"combined_csv.csv\", index=False, encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be171742-aacc-42b0-b679-e37899cc6a65",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['tokenized_sents'] = data.apply(lambda column: nltk.word_tokenize(column['Comment']), axis=1)\n",
    "data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
