{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08d2582b-cf6a-4b6f-9ddc-2a513ea71505",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiment_analysis(picks_ayz, a_comments, symbols):\n",
    "    '''analyzes sentiment anaylsis of top tickers\n",
    "    \n",
    "    Parameter:   picks_ayz: int: top picks to analyze\n",
    "                 a_comments: dict: all the comments to analyze\n",
    "                 symbols: dict: dict of sorted tickers based on mentions\n",
    "    Return:      scores: dictionary: dictionary of all the sentiment analysis\n",
    "    '''\n",
    "    scores = {}\n",
    "     \n",
    "    vader = SentimentIntensityAnalyzer()\n",
    "    vader.lexicon.update(new_words)     # adding custom words from data.py \n",
    "    picks_sentiment = list(symbols.keys())[0:picks_ayz]\n",
    "    \n",
    "    for symbol in picks_sentiment:\n",
    "        stock_comments = a_comments[symbol]\n",
    "        for cmnt in stock_comments:\n",
    "    \n",
    "            emojiless = emoji.get_emoji_regexp().sub(u'', cmnt) # remove emojis\n",
    "            \n",
    "            # remove punctuation\n",
    "            text_punc  = \"\".join([char for char in emojiless if char not in string.punctuation])\n",
    "            text_punc = re.sub('[0-9]+', '', text_punc)\n",
    "                \n",
    "            # tokenizeing and cleaning \n",
    "            tokenizer = RegexpTokenizer('\\w+|\\$[\\d\\.]+|http\\S+')\n",
    "            tokenized_string = tokenizer.tokenize(text_punc)\n",
    "            lower_tokenized = [word.lower() for word in tokenized_string] # convert to lower case\n",
    "            \n",
    "            # remove stop words\n",
    "            nlp = en_core_web_sm.load()\n",
    "            stopwords = nlp.Defaults.stop_words\n",
    "            sw_removed = [word for word in lower_tokenized if not word in stopwords]\n",
    "            \n",
    "            # normalize the words using lematization\n",
    "            lemmatizer = WordNetLemmatizer()\n",
    "            lemmatized_tokens = ([lemmatizer.lemmatize(w) for w in sw_removed])\n",
    "            \n",
    "            # calculating sentiment of every word in comments n combining them\n",
    "            score_cmnt = {'neg': 0.0, 'neu': 0.0, 'pos': 0.0, 'compound': 0.0}\n",
    "            \n",
    "            word_count = 0\n",
    "            for word in lemmatized_tokens:\n",
    "                if word.upper() not in us:\n",
    "                    score = vader.polarity_scores(word)\n",
    "                    word_count += 1\n",
    "                    for key, _ in score.items():\n",
    "                        score_cmnt[key] += score[key]    \n",
    "                else:\n",
    "                    score_cmnt['pos'] = 2.0               \n",
    "                    \n",
    "            # calculating avg.\n",
    "            try:        # handles: ZeroDivisionError: float division by zero\n",
    "                for key in score_cmnt:\n",
    "                    score_cmnt[key] = score_cmnt[key] / word_count\n",
    "            except: pass\n",
    "                \n",
    "            \n",
    "            # adding score the the specific symbol\n",
    "            if symbol in scores:\n",
    "                for key, _ in score_cmnt.items():\n",
    "                    scores[symbol][key] += score_cmnt[key]\n",
    "            else:\n",
    "                scores[symbol] = score_cmnt        \n",
    "    \n",
    "        # calculating avg.\n",
    "        for key in score_cmnt:\n",
    "            scores[symbol][key] = scores[symbol][key] / symbols[symbol]\n",
    "            scores[symbol][key]  = \"{pol:.3f}\".format(pol=scores[symbol][key])\n",
    "            \n",
    "    return scores\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
